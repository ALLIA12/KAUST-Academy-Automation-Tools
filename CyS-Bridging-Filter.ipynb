{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install pandas requests google-auth-oauthlib google-auth-httplib2 google-api-python-client openai PyPDF2"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onFinmuW5WmN",
    "outputId": "81e20eea-9ae5-4b5f-fd91-f7a01b60e527"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
      "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.137.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (2.27.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
      "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.1.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.6.0)\n",
      "Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m367.8/367.8 kB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m232.6/232.6 kB\u001B[0m \u001B[31m13.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.4/76.4 kB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.9/77.9 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m318.9/318.9 kB\u001B[0m \u001B[31m16.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: PyPDF2, jiter, h11, httpcore, httpx, openai\n",
      "Successfully installed PyPDF2-3.0.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.44.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-0VgZx65Sy9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from google.colab import auth\n",
    "from google.auth import default\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from datetime import datetime, timedelta\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import OpenAI\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# # Authenticate and create Google Drive API client\n",
    "# auth.authenticate_user()\n",
    "# creds, _ = default()\n",
    "# drive_service = build('drive', 'v3', credentials=creds)"
   ],
   "metadata": {
    "id": "BlRyIhcq5WAr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set up OpenAI client\n",
    "client = OpenAI(api_key='No leaks!')"
   ],
   "metadata": {
    "id": "_FJVMGQP5e3j"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_pdf_text(pdf_url):\n",
    "    try:\n",
    "        # Check if it's a Google Drive link\n",
    "        if 'drive.google.com' in pdf_url:\n",
    "            # Extract the file ID\n",
    "            file_id = re.findall(r'id=([\\w-]+)', pdf_url)\n",
    "            if not file_id:\n",
    "                file_id = re.findall(r'/d/([\\w-]+)', pdf_url)\n",
    "            if not file_id:\n",
    "                raise ValueError(\"Could not extract Google Drive file ID\")\n",
    "\n",
    "            file_id = file_id[0]\n",
    "            # Construct the direct download link\n",
    "            pdf_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
    "\n",
    "        # Download the PDF\n",
    "        response = requests.get(pdf_url)\n",
    "        response.raise_for_status()  # Raise an exception for bad responses\n",
    "\n",
    "        # Create a PDF reader object\n",
    "        pdf_file = io.BytesIO(response.content)\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "        # Extract text from all pages\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF {pdf_url}: {e}\")\n",
    "        return None"
   ],
   "metadata": {
    "id": "wklYagOtz5hg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def analyze_text_with_gpt(text, prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nText: {text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "metadata": {
    "id": "U2XcPgU15wc3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_cyber_relevance(major):\n",
    "    prompt = \"\"\"\n",
    "    Provide a relevance score from 0 to 1 indicating how closely the major is related to Cybersecurity, Computer Science, or Infomration Technology.\n",
    "    Only return a relevance score, nothing else.\n",
    "    \"\"\"\n",
    "    relevance = analyze_text_with_gpt(major, prompt)\n",
    "    return relevance"
   ],
   "metadata": {
    "id": "m5dpskpX50lT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def parse_date(date_string):\n",
    "    # Remove any leading/trailing whitespace\n",
    "    date_string = date_string.strip()\n",
    "\n",
    "    # Try parsing with different formats\n",
    "    for fmt in ('%Y-%m-%d', '%Y/%m/%d', '%d-%m-%Y', '%d/%m/%Y', '%m-%d-%Y', '%m/%d/%Y'):\n",
    "        try:\n",
    "            return datetime.strptime(date_string, fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # If all else fails, try to extract date using regex\n",
    "    date_pattern = r'\\b\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}\\b|\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{4}\\b'\n",
    "    match = re.search(date_pattern, date_string)\n",
    "    if match:\n",
    "        date_str = match.group(0)\n",
    "        for fmt in ('%Y-%m-%d', '%Y/%m/%d', '%d-%m-%Y', '%d/%m/%Y', '%m-%d-%Y', '%m/%d/%Y'):\n",
    "            try:\n",
    "                return datetime.strptime(date_str, fmt)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    raise ValueError(f\"Unable to parse date string: {date_string}\")"
   ],
   "metadata": {
    "id": "6Imv2f8B53if"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_time_since_graduation(grad_date):\n",
    "    today = datetime.now()\n",
    "    time_since_grad = today - grad_date\n",
    "    years = time_since_grad.days // 365\n",
    "    months = (time_since_grad.days % 365) // 30\n",
    "    return f\"{years} years and {months} months\""
   ],
   "metadata": {
    "id": "9kwSfH9vDdS1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # Access the public Google Sheet\n",
    "    sheet_id = 'NO LEAKS!'\n",
    "    sheet_url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=xlsx'\n",
    "    response = requests.get(sheet_url)\n",
    "    df = pd.read_excel(io.BytesIO(response.content))\n",
    "    qualified_applicants = []\n",
    "    not_qualified_applicants = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            #transcript_url = row['Upload your electronic transcript with selectable text']\n",
    "            #certificate_url = row['Upload your electronic graduation certificate with selectable text']\n",
    "            #transcript_text = extract_pdf_text(transcript_url)\n",
    "            #certificate_text = extract_pdf_text(certificate_url)\n",
    "\n",
    "            # if transcript_text is None or certificate_text is None:\n",
    "            #     print(f\"Skipping applicant {row['National ID Number']} due to PDF extraction error\")\n",
    "            #     continue\n",
    "\n",
    "            gpa, gpa_scale = float(row[\"GPA\"]), int(row[\"GPA Average (Out of 4 or 5)\"])\n",
    "            #print(type(gpa), type(gpa_scale))\n",
    "            cyber_relevance = float(get_cyber_relevance(row[\"Major\"]))\n",
    "            #print(cyber_relevance)\n",
    "            grad_date = row['Graduation Date']\n",
    "            time_since_graduation = calculate_time_since_graduation(grad_date)\n",
    "            #print(time_since_graduation)\n",
    "            english_score = float(row['English proficiency test result'])\n",
    "            if row['English Proficiency Exam'] == 'IELTS':\n",
    "                score_limiter = 6.5\n",
    "            elif row['English Proficiency Exam'] == 'TOEFL':\n",
    "                score_limiter = 79\n",
    "            else:\n",
    "                score_limiter = 105\n",
    "            # Check qualifications\n",
    "            if (cyber_relevance >= 0.7 and\n",
    "                ((gpa_scale == 4 and gpa >= 3.2) or (gpa_scale == 5 and gpa >= 4)) and\n",
    "                english_score >= score_limiter and\n",
    "                (datetime.now() - grad_date) <= timedelta(days=5*365)):\n",
    "\n",
    "                qualified_applicants.append({\n",
    "                    'ID': row['National ID Number'],\n",
    "                    'Name': row['Full Name(As your national ID)'],\n",
    "                    'GPA': f\"{gpa}/{gpa_scale}\",\n",
    "                    'Major': row[\"Major\"],\n",
    "                    'Cybersecurity Relevance': f\"{cyber_relevance:.2f}\",\n",
    "                    'Graduation Date': grad_date.strftime('%Y-%m-%d'),\n",
    "                    'Time Since Graduation': time_since_graduation,\n",
    "                    'English Score': english_score,\n",
    "                    'English exam': row['English Proficiency Exam']\n",
    "\n",
    "                })\n",
    "            else:\n",
    "                not_qualified_applicants.append({\n",
    "                    'ID': row['National ID Number'],\n",
    "                    'Name': row['Full Name(As your national ID)'],\n",
    "                    'GPA': f\"{gpa}/{gpa_scale}\",\n",
    "                    'Major': row[\"Major\"],\n",
    "                    'Cybersecurity Relevance': f\"{cyber_relevance:.2f}\",\n",
    "                    'Graduation Date': grad_date.strftime('%Y-%m-%d'),\n",
    "                    'Time Since Graduation': time_since_graduation,\n",
    "                    'English Score': english_score,\n",
    "                    'English exam': row['English Proficiency Exam']\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing applicant {row['National ID Number']}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Qualified Applicants:\")\n",
    "    for applicant in qualified_applicants:\n",
    "        print(f\"ID: {applicant['ID']}, Name: {applicant['Name']}, GPA: {applicant['GPA']}, \"\n",
    "              f\"Major: {applicant['Major']}, Cybersecurity Relevance: {applicant['Cybersecurity Relevance']}, \"\n",
    "              f\"Graduation Date: {applicant['Graduation Date']}, Time Since Graduation: {applicant['Time Since Graduation']}, English Score {applicant['English Score']}, English Exam {applicant['English exam']}\")\n",
    "\n",
    "    print(\"Not Qualified Applicants:\")\n",
    "    for applicant in not_qualified_applicants:\n",
    "        print(f\"ID: {applicant['ID']}, Name: {applicant['Name']}, GPA: {applicant['GPA']}, \"\n",
    "              f\"Major: {applicant['Major']}, Cybersecurity Relevance: {applicant['Cybersecurity Relevance']}, \"\n",
    "              f\"Graduation Date: {applicant['Graduation Date']}, Time Since Graduation: {applicant['Time Since Graduation']},  English Score {applicant['English Score']}, English Exam {applicant['English exam']}\")"
   ],
   "metadata": {
    "id": "7SU-1a4w55mY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zE-IlCL5_FE",
    "outputId": "aa74cea0-7f93-4039-c830-bae7dd1e8ea4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# cybersecurity_relevant_majors = [\n",
    "#     \"Cybersecurity\",\n",
    "#     \"Computer Science\",\n",
    "#     \"Information Technology\",\n",
    "#     \"Network Security\",\n",
    "#     \"Information Security\",\n",
    "#     \"Software Engineering\",\n",
    "#     \"Computer Engineering\",\n",
    "#     \"Data Science\",\n",
    "#     \"Cryptography\",\n",
    "#     \"Digital Forensics\",\n",
    "#     \"Cloud Computing\",\n",
    "#     \"Network Administration\",\n",
    "#     \"Systems Engineering\",\n",
    "#     \"Security Management\",\n",
    "#     \"Information Systems\",\n",
    "#     \"Penetration Testing\",\n",
    "#     \"Ethical Hacking\",\n",
    "#     \"Artificial Intelligence\",\n",
    "#     \"Risk Management\",\n",
    "#     \"Incident Response\"\n",
    "#     ''\n",
    "# ]\n",
    "\n",
    "\n",
    "# for item in cybersecurity_relevant_majors:\n",
    "#     print(item, get_cyber_relevance(item))"
   ],
   "metadata": {
    "id": "Rrdk9jVz6i49"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(get_cyber_relevance(\"Chemistry\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDXT6k1g6-Vz",
    "outputId": "524aa928-8b83-445f-be44-cc4d9d321b2d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "QgGXMTJF7E-S"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
